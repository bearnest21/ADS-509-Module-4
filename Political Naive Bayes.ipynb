{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('conventions',)]\n"
     ]
    }
   ],
   "source": [
    "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(convention_cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Skip to content The Company Careers Press Free...</td>\n",
       "      <td>127</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:33</td>\n",
       "      <td>Iâ€™m here by calling the full session of the 48...</td>\n",
       "      <td>41</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>1</td>\n",
       "      <td>00:59</td>\n",
       "      <td>Every four years, we come together to reaffirm...</td>\n",
       "      <td>17</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Kerry Washington</td>\n",
       "      <td>1</td>\n",
       "      <td>01:07</td>\n",
       "      <td>We fight for a more perfect union because we a...</td>\n",
       "      <td>28</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>1</td>\n",
       "      <td>01:18</td>\n",
       "      <td>We must come together to defeat Donald Trump, ...</td>\n",
       "      <td>22</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  1                 2  3      4  \\\n",
       "0  Democratic  4           Unknown  1  00:00   \n",
       "1  Democratic  4         Speaker 1  1  00:33   \n",
       "2  Democratic  4         Speaker 2  1  00:59   \n",
       "3  Democratic  4  Kerry Washington  1  01:07   \n",
       "4  Democratic  4    Bernie Sanders  1  01:18   \n",
       "\n",
       "                                                   5    6  \\\n",
       "0  Skip to content The Company Careers Press Free...  127   \n",
       "1  Iâ€™m here by calling the full session of the 48...   41   \n",
       "2  Every four years, we come together to reaffirm...   17   \n",
       "3  We fight for a more perfect union because we a...   28   \n",
       "4  We must come together to defeat Donald Trump, ...   22   \n",
       "\n",
       "                                                   7  \n",
       "0  www_rev_com_blog_transcripts2020-democratic-na...  \n",
       "1  www_rev_com_blog_transcripts2020-democratic-na...  \n",
       "2  www_rev_com_blog_transcripts2020-democratic-na...  \n",
       "3  www_rev_com_blog_transcripts2020-democratic-na...  \n",
       "4  www_rev_com_blog_transcripts2020-democratic-na...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first look at what the table in the DF looks like\n",
    "col = pd.DataFrame(convention_cur.execute(\"\"\"SELECT * FROM conventions\"\"\"))\n",
    "col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party FROM conventions\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    # store the results in convention_data\n",
    "    \n",
    "    text, party = row\n",
    "    \n",
    "    # The  first element in the sublist should be the cleaned \n",
    "    # and tokenized text in a single string\n",
    "    \n",
    "    #********* Removing the punctuations ***************\n",
    "    punctuation = set(punctuation) # creating punctuation Set\n",
    "    more_punct_elements = [\"â€º\", \"Â«\", \"Ã—\"]\n",
    "    punctuation.update(more_punct_elements) # updating our punctuation sets\n",
    "    \n",
    "    \n",
    "    text_no_punct = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "    \n",
    "    #********* Removing the numbers ***************\n",
    "    \n",
    "    text_no_numbers = \"\".join([ch for ch in text_no_punct if not ch.isdigit()])\n",
    "    \n",
    "    #********* Tokenizing ***************\n",
    "    whitespace_pattern = re.compile(r\"\\s+\")\n",
    "    \n",
    "    tokens = [item.lower() for item in whitespace_pattern.split(text_no_numbers)]\n",
    "    \n",
    "    #*********** Removing Stopwords **************\n",
    "    sw = stopwords.words(\"english\") # stopwords\n",
    "    \n",
    "    tokens_no_sw = [token for token in tokens if not token in sw]\n",
    "    \n",
    "    #********* From tokenized into  single string *************\n",
    "    \n",
    "    # tokenized text in a single string\n",
    "    \n",
    "    text_tokenized = \" \".join(tokens_no_sw)\n",
    "    \n",
    "    #********* Appending to convention_data ***************\n",
    "    # The second element should be the party\n",
    "    \n",
    "    convention_data.append([text_tokenized, party])\n",
    "    \n",
    "# print(convention_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['behalf united states', 'Republican'],\n",
       " ['idaho', 'Democratic'],\n",
       " ['times challenging believe thereâ€™s one way forward united america united america united pursuit perfect union united dreams better future us children united determination make coming years bright ready believe great nation weâ€™re good decent people lordâ€™s sake united states america thereâ€™s never anything weâ€™ve able accomplish weâ€™ve done together',\n",
       "  'Democratic'],\n",
       " ['immediately upon taking office president trump changed things change threatened establishment establishment fought back democrat obstruction phony investigations dishonest media incredible stories negative president seen anything like despite everything threw president trump delivered american people delivered like never building strongest economy american history million new jobs lowest ever unemployment black hispanic americans ending biden era lopsided trade deals sent factories overseas passing historic usmca taking china winning trade war protecting strengthening medicare social security lowering cost insulin delivering first real drop drug prices years restoring military fixing va bringing troops home taking worldâ€™s deadliest terrorists battlefield soleimani al baghdadi isis brought justice',\n",
       "  'Republican'],\n",
       " ['cut', 'Democratic'],\n",
       " ['democracy beautiful', 'Democratic'],\n",
       " ['iâ€™m grateful spotlight president trump putting new york city public housing think itâ€™s wrong democrats put illegal immigrants black americans people waiting waiting list new york city public housing years yet legal immigrants living something wrong picture',\n",
       "  'Republican'],\n",
       " ['good evening iâ€™m senator rand paul kentucky donald trump met many years ago running anything first met recall struck earth seemed like normal guy okay normal guy plane helicopter whoâ€™s counting planning medical mission trip guatemala perform charity eye surgeries needed money fund trip donald trump offered help immediately came us support medical mission guatemala also contributed another mission trip haiti year later performed hundreds cataract surgeries countries nothing amazing removing bandages personâ€™s eyes watching see loved ones',\n",
       "  'Republican'],\n",
       " ['america land opportunity country resolution succeed important abraham lincolnâ€™s words years ago still resonate today country boy born poverty log cabin raised right frontier indiana could educate become lawyer become president united states would preserve union abolish slavery save nation fellow hoosier visiting lincolnâ€™s boyhood home always treasured experience family itâ€™s place made lincoln shaped lincoln defined man lincoln would become america land opportunity president donald trump declared mount rushmore america anything anything together achieve anything',\n",
       "  'Republican'],\n",
       " ['four years imagine achieve simply working president believe presidentâ€™s vision future stand tonight calling americans join us doesnâ€™t matter look like love worship gender job youâ€™re traditional democrat whoâ€™s become disillusioned radical party become stand us welcome america needs patriots rush defense fellow americans promise tent free free speak truth choose journey define life power go far aim aim higher keep going americans idealists dreamers lovers adventure weâ€™re rugged independent donâ€™t make excuses make impossible reality',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2338 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    ret_dict = dict()\n",
    "\n",
    "    for i in text.split():\n",
    "    \n",
    "        if i in fw:\n",
    "\n",
    "            ret_dict[i] = True\n",
    "    \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "The largest differences in tokens used by republicans vs democrats is the word China.  This at a rate of almost 25:1.  also interesting is the fact the word \"destroy\" shows up at a rate of 20:1.  The context of these words would be very interesting to explore.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "for row in results:\n",
    "    # store the results in convention_data\n",
    "    \n",
    "    candidate, party, text = row\n",
    "    \n",
    "    # The  first element in the sublist should be the cleaned \n",
    "    # and tokenized text in a single string\n",
    "    \n",
    "    #************* Decoding the Bytes ******************\n",
    "    text_decoded = text.decode('utf-8')\n",
    "    \n",
    "    #********* Removing the punctuations ***************\n",
    "    punctuation = set(punctuation) # creating punctuation Set\n",
    "    more_punct_elements = [\"â€º\", \"Â«\", \"Ã—\"]\n",
    "    punctuation.update(more_punct_elements) # updating our punctuation sets\n",
    "    \n",
    "    \n",
    "    text_no_punct = \"\".join([ch for ch in text_decoded if ch not in punctuation])\n",
    "    \n",
    "    #********* Removing the numbers ***************\n",
    "    \n",
    "    text_no_numbers = \"\".join([ch for ch in text_no_punct if not ch.isdigit()])\n",
    "    \n",
    "    #********* Tokenizing ***************\n",
    "    whitespace_pattern = re.compile(r\"\\s+\")\n",
    "    \n",
    "    tokens = [item.lower() for item in whitespace_pattern.split(text_no_numbers)]\n",
    "    \n",
    "    #*********** Removing Stopwords **************\n",
    "    sw = stopwords.words(\"english\") # stopwords\n",
    "    \n",
    "    tokens_no_sw = [token for token in tokens if not token in sw]\n",
    "    \n",
    "    #********* From tokenized into  single string *************\n",
    "    \n",
    "    # tokenized text in a single string\n",
    "    \n",
    "    text_tokenized = \" \".join(tokens_no_sw)\n",
    "    \n",
    "    #********* Appending to convention_data ***************\n",
    "    # The second element should be the party\n",
    "    \n",
    "    tweet_data.append([text_tokenized, party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrztvv\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe rallytogether httpstconxutfll\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget httpstcockyqotqh\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: weâ€™re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line httpstcoezpvvmiz\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: letâ€™s make even greater kag ðŸ‡ºðŸ‡¸ httpstcoyqozdlz\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: hr cavs tie series im allin repbarbaralee scared roadtovictory\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serveâ€¦ httpstcofkvmwcqdi\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close raised toward match right whoot thatâ€™s nonmath majors room ðŸ˜‚ help us get httpstcotucsd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potusâ€™s plan expand offshore drilling opened public days march share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastlaâ€™s years eastside commitment amp saluted community leaders last nightâ€™s awards dinner httpstcovghgivb\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    featureset = conv_features(tweet, feature_words)\n",
    "    \n",
    "    estimated_party = classifier.classify(featureset)\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    featureset = conv_features(tweet, feature_words)\n",
    "\n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(featureset)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3743, 'Democratic': 629}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4779, 'Democratic': 851})})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "The classifier looked at 10000 different tweets, in an attempt to classify them as either republican or democrat.  It seems clear that this classifier is much better at detecting republicans vice democrats.  This could be because of poor or missing labels for tweets related to democrats."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
